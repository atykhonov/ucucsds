<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>README.html</title>

</head>

<body>

<h1>Launch master instance</h1>
<p><img alt="Launch" src="./images/launch.png" /></p>
<p>Click <code>Launch Instance</code>.</p>
<h2>Step 1: Choose an Amazon Machine Image (AMI)</h2>
<p><img alt="Quick Start" src="./images/quick-start.png" /></p>
<p>Select <code>Community AMIs</code>. Check <code>Red Hat</code> checkbox.</p>
<p><img alt="Select RHEL" src="./images/rhel.png" /></p>
<p>Then click <code>Select</code>.</p>
<p><img alt="Select RHEL" src="./images/select-rhel.png" /></p>
<h2>Step 2: Choose an Instance Type</h2>
<p>Choose <code>t2.large</code> and click <code>Next: Configure Instance Details</code>.</p>
<p><img alt="Choose instance type" src="./images/instance-type.png" /></p>
<h2>Step 3: Configure Instance Details</h2>
<p>If you don't have any network (VPC) please create it. Please create subnet as well, if there is no any subnet in the list.</p>
<p>Please change <code>Auto-assign Public IP</code> to <code>Enable</code>.</p>
<p><img alt="Configure instance details" src="./images/configure-instance.png" /></p>
<p>Click <code>Next: Add Storage</code>.</p>
<h2>Step 4: Add Storage</h2>
<p>Input into the field <code>Size (GiB)</code> value <code>25</code>. Click <code>Next: Tag Instance</code>.</p>
<p><img alt="Storage" src="./images/add-storage.png" /></p>
<h2>Step 5: Tag Instance</h2>
<p>Just click <code>Next: Configure Security Group</code>.</p>
<h2>Step 6: Configure Security Group</h2>
<p>Select <code>All traffic</code> from select-box <code>Type</code> and click <code>Review and Launch</code>.</p>
<p><img alt="Configure security group" src="./images/security-group.png" /></p>
<h2>Step 7: Review Instance Launch</h2>
<p>Click <code>Launch</code>!</p>
<p><img alt="Review" src="./images/review.png" /></p>
<h2>Select an existing key pair or create a new key pair</h2>
<p>Select "Create a new key pair" and input key pair name (e.g. <code>cloudera</code>), then click <code>Download Key Pair</code> and save the file. After that the <code>Launch Instances</code> button will become enabled. Click it.</p>
<p><img alt="Key pair" src="./images/key-pair.png" /></p>
<h2>Launch status</h2>
<p>Here you can see launch status. Click on <code>View Instances</code>.</p>
<p><img alt="Launch status" src="./images/launch-status.png" /></p>
<h2>Instances</h2>
<p>Here we can see the list of launched instances.</p>
<p><img alt="Launched instances" src="./images/instances-list.png" /></p>
<p>Before connection to the instance, please change permissions for the recently downloaded <code>cloudera.pem</code> file:</p>
<p><code>chmod 600 cloudera.pem</code></p>
<p>On top of the list you can see the running instance. The one which has been recently created.</p>
<p>From the bottom panel take <code>Public IP</code> of the instance and put it to <code>/etc/hosts</code> (please, don't do it in this way if you did it once for <code>master.cloudera</code>. Edit <code>/etc/hosts</code> using any text editor instead and modify existing record):</p>
<p>```
sudo -s</p>
<p>echo "54.146.201.153 master.cloudera" &gt;&gt; /etc/hosts
```</p>
<p>Then, on the local machine execute the following in order to connect to master instance:</p>
<p><code>ssh -i cloudera.pem ec2-user@master.cloudera</code></p>
<p>Please specify the full path to the <code>cloudera.pem</code> if it is not located in the current directory. You might be asked: <code>Are you sure you want to continue connecting (yes/no)?</code>. Say: yes!</p>
<p>As the result you should get the shell:</p>
<p><img alt="Shell" src="./images/shell.png" /></p>
<p>Welcome, you're on master instance!</p>
<h1>Launch slave instance</h1>
<p>In order to launch slave, you could perform the same steps as for master, except the following:</p>
<p>1) Select <code>t2.small</code> instance type.</p>
<p>2) You don't need to create a network or subnet (select existing one).</p>
<p>3) Please, don't forget to change <code>Auto-assign Public IP</code> to <code>Enable</code>.</p>
<p>4) Select an existing key pair (e.g. cloudera.pm).</p>
<h2>Check that you can connect to slave</h2>
<p>Take the <code>Public IP</code> of slave instance and put it to <code>/etc/hosts</code> (please, don't do it in this way if you did it once for <code>slave.cloudera</code>. Edit <code>/etc/hosts</code> using any text editor instead and modify existing record):</p>
<p>```
sudo -s</p>
<p>echo "107.22.45.103 slave.cloudera" &gt;&gt; /etc/hosts
```</p>
<p>Try to connect to it:</p>
<p><code>ssh -i cloudera.pem ec2-user@slave.cloudera</code></p>
<p>Welcome, you're on slave instance!</p>
<h1>Configure the instances</h1>
<h2>Getting private IPs</h2>
<p>First of all let's get private IPs of the instances. Go to master instance:</p>
<p><code>ssh -i cloudera.pem ec2-user@master.cloudera</code></p>
<p>And execute there <code>ifconfig</code>:</p>
<p><code>ifconfig</code></p>
<p>You should get the following in response:</p>
<p><img alt="Private IP" src="./images/private-ip.png" /></p>
<p>The private IP in my case is <code>172.30.243.82</code>. Remember it or better write it down :)</p>
<p>Please perform the same for slave instance and write down its private IP.</p>
<p>In my case it equals to <code>172.30.169.105</code>.</p>
<h2>Disable SELinux</h2>
<p>Connect to master instance:</p>
<p><code>ssh -i cloudera.pem ec2-user@master.cloudera</code></p>
<p>In order to disable SELinux execute the following command:</p>
<p><code>sudo sed -i 's/SELINUX=enforcing/SELINUX=disabled/g;' /etc/sysconfig/selinux</code></p>
<p>Please check:</p>
<p><code>cat /etc/sysconfig/selinux</code></p>
<p>In the output you should see <code>SELINUX=disabled</code>.</p>
<p>Now, please executed the following command:</p>
<p><code>sudo sed -i 's/LANG=en_US.UTF-8/LANG=en_US.UTF-8 selinux=0/g;' /boot/grub2/grub.cfg</code></p>
<p>Please check:</p>
<p><code>sudo cat /boot/grub2/grub.cfg</code></p>
<p>Please check that there is <code>selinux=0</code> in the end of line with <code>/boot/vmlinuz-...</code>.</p>
<p><code>menuentry 'Red Hat Enterprise Linux Server (3.10.0-327.el7.x86_64) 7.2 (Maipo)' --class red --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-327.el7.x86_64-advanced-379de64d-ea11-4f5b-ae6a-0aa50ff7b24d' {
        load_video
        set gfxpayload=keep
        insmod gzio
        insmod part_gpt
        insmod xfs
        set root='hd0,gpt2'
        if [ x$feature_platform_search_hint = xy ]; then
          search --no-floppy --fs-uuid --set=root --hint='hd0,gpt2'  379de64d-ea11-4f5b-ae6a-0aa50ff7b24d
        else
          search --no-floppy --fs-uuid --set=root 379de64d-ea11-4f5b-ae6a-0aa50ff7b24d
        fi
        linux16 /boot/vmlinuz-3.10.0-327.el7.x86_64 root=UUID=379de64d-ea11-4f5b-ae6a-0aa50ff7b24d ro console=ttyS0,115200n8 console=tty0 net.ifnames=0 crashkernel=auto LANG=en_US.UTF-8 selinux=0
        initrd16 /boot/initramfs-3.10.0-327.el7.x86_64.img</code></p>
<p>Now, please reboot your instance:</p>
<p><code>sudo reboot</code></p>
<p>After a while connect again to master instance and execute:</p>
<p><code>getenforce</code></p>
<p>You should receive in response:</p>
<p><code>Disabled</code></p>
<p>SELinux is successfully disabled!</p>
<p><strong>Perform exactly the same steps for slave instance!</strong></p>
<h2>Configure hosts</h2>
<h3>Configure master instance</h3>
<p>Connect to master instance:</p>
<p><code>ssh -i cloudera.pem ec2-user@master.cloudera</code></p>
<p>Execute the following commands:</p>
<p>```
sudo -s</p>
<p>echo "172.30.243.82 master.cloudera" &gt;&gt; /etc/hosts</p>
<p>echo "172.30.169.105 slave.cloudera" &gt;&gt; /etc/hosts</p>
<p>exit
```</p>
<p>172.30.243.82 - private IP of master instance.</p>
<p>172.30.169.105 - private IP of slave instance.</p>
<p>Check that the records are present:</p>
<p><code>cat /etc/hosts</code></p>
<p>You should get something like the following in output:</p>
<p>```
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</p>
<p>172.30.243.82 master.cloudera
172.30.169.105 slave.cloudera
```</p>
<p>Now, please, execute the following command:</p>
<p>```
sudo -s</p>
<p>echo "master.cloudera" &gt; /etc/hostname</p>
<p>echo "HOSTNAME=master.cloudera" &gt;&gt; /etc/sysconfig/network</p>
<p>echo "preserve_hostname: true" &gt;&gt; /etc/cloud/cloud.cfg</p>
<p>exit
```</p>
<p>Now reboot:</p>
<p><code>sudo reboot</code></p>
<p>Connect again and check:</p>
<p><code>hostname</code></p>
<p>The output should be <code>master.cloudera</code>.</p>
<p><code>hostname --fqdn</code></p>
<p>Here should be the same output: <code>master.cloudera</code>.</p>
<p>Our host name has been successfully changed!</p>
<h3>Configure slave instance</h3>
<p>Now, we will be configuring slave instance using mostly the same steps (but not the same, be careful) as for master.</p>
<p>Connect to slave:</p>
<p><code>ssh -i cloudera.pem ec2-user@slave.cloudera</code></p>
<p>Execute the following:</p>
<p>```
sudo -s</p>
<p>echo "172.30.243.82 master.cloudera" &gt;&gt; /etc/hosts</p>
<p>echo "172.30.169.105 slave.cloudera" &gt;&gt; /etc/hosts</p>
<p>exit
```</p>
<p>Check that the records are present:</p>
<p><code>cat /etc/hosts</code></p>
<p>You should get something like the following in output:</p>
<p>```
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</p>
<p>172.30.243.82 master.cloudera
172.30.169.105 slave.cloudera
```</p>
<p>Now, please, execute the following command:</p>
<p>```
sudo -s</p>
<p>echo "slave.cloudera" &gt; /etc/hostname</p>
<p>echo "HOSTNAME=slave.cloudera" &gt;&gt; /etc/sysconfig/network</p>
<p>echo "preserve_hostname: true" &gt;&gt; /etc/cloud/cloud.cfg</p>
<p>exit
```</p>
<p>Now reboot:</p>
<p><code>sudo reboot</code></p>
<p>Connect again and check:</p>
<p><code>hostname</code></p>
<p>The output should be <code>slave.cloudera</code>.</p>
<p><code>hostname --fqdn</code></p>
<p>Here should be the same output: <code>slave.cloudera</code>.</p>
<p>Our host name has been successfully changed!</p>
<h1>Install cloudera</h1>
<p>Connect to master:</p>
<p><code>ssh -i cloudera.pem ec2-user@master.cloudera</code></p>
<p>Then download cloudera:</p>
<p>```
sudo yum install -y wget</p>
<p>wget http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin</p>
<p>chmod +x cloudera-manager-installer.bin</p>
<p>sudo ./cloudera-manager-installer.bin
```</p>
<p><img alt="Cloudera installation" src="./images/cloudera-installation.png" /></p>
<p>Click <code>Next</code>, then <code>Next</code>, accept the license, click <code>Next</code>, accept the license again, and wait until it will be installed.</p>
<p>When installation is finished, the wizard prompts you to visit <code>http://master.cloudera:7180/</code>. Do it!</p>
<h1>Cloudera configuration</h1>
<p>Open <code>http://master.cloudera:7180/</code> and you'll get login page. Use username <code>admin</code> and password <code>admin</code>. (If you don't see login page, but "Unable to load page" instead, just wait for a while and try again).</p>
<h2>End User License Terms and Conditions</h2>
<p>Check <code>Yes, I accept the End User License Terms and Conditions.</code> and click <code>Continue</code>.</p>
<h2>Which edition do you want to deploy?</h2>
<p>Click <code>Continue</code>.</p>
<h2>Thank you for choosing Cloudera Manager and CDH.</h2>
<p>Click <code>Continue</code>.</p>
<h2>Specify hosts for your CDH cluster installation.</h2>
<p><img alt="Specify hosts" src="./images/specify-hosts.png" /></p>
<p>Enter private IP of master and click <code>Search</code>.</p>
<p><img alt="Specify hosts 2" src="./images/specify-hosts-2.png" /></p>
<p>Master is selected, click <code>Continue</code>.</p>
<h2>Select Repository</h2>
<p>Click <code>Continue</code>.</p>
<h2>JDK Installation Options</h2>
<p>Check <code>Install Oracle Java SE Development Kit (JDK)</code> and click <code>Continue</code>.</p>
<p><img alt="JDK installation" src="./images/jdk-installation.png" /></p>
<h2>Enable Single User Mode</h2>
<p>Click <code>Continue</code>.</p>
<h2>Provide SSH login credentials.</h2>
<p>Select <code>Another user</code> and input <code>ec2-user</code>. Then select <code>Authentication Method</code> equals to <code>All hosts accept same private key</code>, click on <code>Choose File</code> and open <code>cloudera.pem</code> file. Click <code>Continue</code>. You will be asked: <code>Continue SSH login with no passphrase?</code>. Say: Ok!</p>
<h2>Installation in progress.</h2>
<p>We need to wait for a while and click <code>Continue</code>.</p>
<h2>Installing Selected Parcels</h2>
<p>Coffee time (~5m). After coffee break click <code>Continue</code>.</p>
<h2>Inspect hosts for correctness</h2>
<p>Most probably you'll see the same errors as could be seen on the screenshot:</p>
<p><img alt="SSH credentials" src="./images/inspect-hosts.png" /></p>
<p>So, in order to fix them execute the following (master instance):</p>
<p>```
sudo -s</p>
<p>sysctl vm.swappiness=10</p>
<p>echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</p>
<p>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</p>
<p>exit
```</p>
<p>Click <code>Run Again</code>. The errors should be absent. Click <code>Finish</code>.</p>
<h2>Choose the CDH 5 services that you want to install on your cluster</h2>
<p>Select <code>Custom Services</code>, then <code>HBase</code>, <code>HDFS</code>, <code>MapReduce</code> and <code>YARN</code>. Click <code>Continue</code>.</p>
<h2>Customize Role Assignments</h2>
<p>Click <code>Continue</code>.</p>
<h2>Database Setup</h2>
<p>Click <code>Test Connection</code> then <code>Continue</code>.</p>
<h2>Review Changes</h2>
<p>Click <code>Continue</code>.</p>
<h2>First Run</h2>
<p>Pray!</p>
<h2>Congratulations!</h2>
<p>Click <code>Finish</code>.</p>
<h1>Cloudera Manager</h1>
<h2>Fix errors</h2>
<p>At this point several errors could be seen. There was another one with ZooKeeper which was fixed by means of restarting of ZooKeeper. Just click on the arrow and click <code>Restart</code>.</p>
<p><img alt="Cloudera Manager Home" src="./images/cloudera-manager-home.png" /></p>
<p>After a while all other errors disappeared except for HDFS.</p>
<p>Click on red exclamation sign.</p>
<p><img alt="HDFS Exclamation Sign" src="./images/hdfs-exclamation-mark.png" /></p>
<p>Click <code>Under-Replicated Blocks</code>.</p>
<p><img alt="Under-Replicated Blocks" src="./images/under-replicated.png" /></p>
<p>Click on <code>Change Under-replicated Block Monitoring Thresholds for this service</code>.</p>
<p><img alt="Under-Replicated Configuration" src="./images/under-replicated-configuration.png" /></p>
<p>Input <code>90</code> into <code>Critical</code> input field and <code>Save Changes</code>.</p>
<p>Now, go to home page and see that instead of error we have the warning.</p>
<h2>HDFS configuration</h2>
<p>On the home page click <code>HDFS</code> link (<code>Status</code> section).</p>
<p>Click <code>Configuration</code> and input <code>dfs.permissions</code>.</p>
<p><img alt="dfs permissions" src="./images/dfs-permissions.png" /></p>
<p>Uncheck <code>HDFS (Service-Wide)</code> and click <code>Save Changes</code>.</p>
<p><img alt="hdfs restart" src="./images/restart-hdfs.png" /></p>
<p>Near <code>Actions</code> button you'll see restart button. Click it.</p>
<p><img alt="restart stale services" src="./images/restart-stale-services.png" /></p>
<p>Click <code>Restart Stale Services</code>.</p>
<p><img alt="restart now" src="./images/restart-now.png" /></p>
<p>Check <code>Re-deploy client configuration</code> and click <code>Restart Now</code>.</p>
<p>After a while the services will be restarted.</p>
<p><img alt="services restarted" src="./images/services-restarted.png" /></p>
<p>Click <code>Finish</code>.</p>
<h2>YARN configuration</h2>
<p>On the home page click <code>YARN (MR2 Included)</code> link.</p>
<p>Go to <code>Configuration</code> page and input <code>yarn.nodemanager.resource.memory-mb</code>.</p>
<p><img alt="yarn memory" src="./images/yarn-memory.png" /></p>
<p>Input <code>2.5</code>. Please make sure that <code>GiB</code> is selected. Click <code>Save Changes</code>.</p>
<p>Now, instead of <code>yarn.nodemanager.resource.memory-mb</code> please input <code>yarn.scheduler.minimum-allocation-mb</code>.</p>
<p><img alt="minimum allocation" src="./images/minimum-allocation.png" /></p>
<p>Input <code>750</code> and make sure that <code>MiB</code> is selected. Click <code>Save Changes</code>.</p>
<p><img alt="redeployment" src="./images/redeployment.png" /></p>
<p>Near <code>Actions</code> button you can see two icons. Click on the second one (redeployment).</p>
<p>On the next screen click <code>Restart Stale Services</code>. And then click <code>Restart Now</code>.</p>
<p>After a while all services will be restarted. Click <code>Finish</code>.</p>
<h2>Execution of test application on a single node (master)</h2>
<p>Download test application <code>wordcount-1.0-SNAPSHOT-jar-with-dependencies.jar</code> and upload it to master by means of the following command:</p>
<p><code>scp -i cloudera.pem wordcount-1.0-SNAPSHOT-jar-with-dependencies.jar ec2-user@master.cloudera:/home/ec2-user/</code></p>
<p>Connect to master instance:</p>
<p><code>ssh -i cloudera.pem ec2-user@master.cloudera</code></p>
<p>Then execute the following commands:</p>
<p>```
sudo su hdfs</p>
<p>hadoop fs -mkdir /home /home/root</p>
<p>hadoop fs -chown root /home/root</p>
<p>exit</p>
<p>sudo -s</p>
<p>hadoop fs -mkdir /home/root/wordcount /home/root/wordcount/input</p>
<p>echo "Hadoop is an elephant" &gt; file0</p>
<p>echo "Hadoop is as yellow as can be" &gt; file1</p>
<p>echo "Oh what a yellow fellow is Hadoop" &gt; file2</p>
<p>hadoop fs -put file* /home/root/wordcount/input</p>
<p>hadoop jar wordcount-1.0-SNAPSHOT-jar-with-dependencies.jar WordCount /home/root/wordcount/input /home/root/wordcount/output
```</p>
<p>The following output could be seen in response:</p>
<p>```
16/11/02 06:19:31 INFO client.RMProxy: Connecting to ResourceManager at master.cloudera/172.30.191.118:8032
16/11/02 06:19:32 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.</p>
<p>16/11/02 06:19:34 INFO input.FileInputFormat: Total input paths to process : 3
16/11/02 06:19:35 INFO mapreduce.JobSubmitter: number of splits:3
16/11/02 06:19:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1478081832568_0001
16/11/02 06:19:36 INFO impl.YarnClientImpl: Submitted application application_1478081832568_0001
16/11/02 06:19:36 INFO mapreduce.Job: The url to track the job: http://master.cloudera:8088/proxy/application_1478081832568_0001/
16/11/02 06:19:36 INFO mapreduce.Job: Running job: job_1478081832568_0001
16/11/02 06:19:47 INFO mapreduce.Job: Job job_1478081832568_0001 running in uber mode : false
16/11/02 06:19:47 INFO mapreduce.Job:  map 0% reduce 0%
16/11/02 06:19:55 INFO mapreduce.Job:  map 33% reduce 0%
16/11/02 06:19:59 INFO mapreduce.Job:  map 67% reduce 0%
16/11/02 06:20:06 INFO mapreduce.Job:  map 100% reduce 0%
16/11/02 06:20:13 INFO mapreduce.Job:  map 100% reduce 100%
16/11/02 06:20:14 INFO mapreduce.Job: Job job_1478081832568_0001 completed successfully
16/11/02 06:20:14 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=143
                FILE: Number of bytes written=489960
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=458
                HDFS: Number of bytes written=80
                HDFS: Number of read operations=12
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters 
                Launched map tasks=3
                Launched reduce tasks=1
                Data-local map tasks=3
                Total time spent by all maps in occupied slots (ms)=31530
                Total time spent by all reduces in occupied slots (ms)=9136
                Total time spent by all map tasks (ms)=15765
                Total time spent by all reduce tasks (ms)=4568
                Total vcore-seconds taken by all map tasks=15765
                Total vcore-seconds taken by all reduce tasks=4568
                Total vcore-seconds taken by all map tasks=15765                                                                            [0/108]
                Total vcore-seconds taken by all reduce tasks=4568
                Total megabyte-seconds taken by all map tasks=16143360
                Total megabyte-seconds taken by all reduce tasks=4677632
        Map-Reduce Framework
                Map input records=3
                Map output records=18
                Map output bytes=158
                Map output materialized bytes=224
                Input split bytes=372
                Combine input records=18
                Combine output records=17
                Reduce input groups=12
                Reduce shuffle bytes=224
                Reduce input records=17
                Reduce output records=12
                Spilled Records=34
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=241
                CPU time spent (ms)=2290
                Physical memory (bytes) snapshot=1526329344
                Virtual memory (bytes) snapshot=6335172608
                Total committed heap usage (bytes)=1474822144
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=86
        File Output Format Counters 
                Bytes Written=80
```</p>
<p>So far so good!</p>
<h2>Check the results of the execution</h2>
<p>Go to <code>YARN (MR2 Included)</code>. Then open <code>Applications</code> page.</p>
<p><img alt="yarn applications" src="./images/yarn-applications-page.png" /></p>
<p>You can see the results of executed application.</p>
<p>Go to <code>Web UI</code> -&gt; <code>ResourceManager Web UI (master)</code>.</p>
<p><img alt="hadoop applications" src="./images/hadoop-applications.png" /></p>
<p>Click on application link (e.g. <code>application_1478081832568_0001</code>).</p>
<p><img alt="applications history" src="./images/hadoop-applications-history.png" /></p>
<p>Click <code>History</code> link.</p>
<p><img alt="services restarted" src="./images/hadoop-application-job.png" /></p>
<p>Click <code>3</code> link, in <code>Maps</code> row, <code>Successfull</code> column.</p>
<p><img alt="succesful map attempts" src="./images/successful-map-attempts.png" /></p>
<h2>Execution of test application on master and slave</h2>
<p>Go to <code>Cloudera Manager</code>. Then <code>Hosts</code> -&gt; <code>All Hosts</code>.</p>
<p><img alt="all hosts" src="./images/all-hosts.png" /></p>
<p>Click <code>Add New Hosts to Cluster</code>.</p>
<p>On the next screen click <code>Continue</code>.</p>
<h3>Specify hosts for your CDH cluster installation.</h3>
<p><img alt="specify hosts slave" src="./images/specify-hosts-slave.png" /></p>
<p>Input private IP of slave instance and click <code>Search</code>.</p>
<p>Slave instance is selected. Click <code>Continue</code>.</p>
<p><img alt="select repository" src="./images/select-repository-slave.png" /></p>
<p>Click <code>Continue</code>.</p>
<p><img alt="jdk installation slave" src="./images/jdk-installation-slave.png" /></p>
<p>Check <code>Install Oracle Java SE Development Kit (JDK)</code> and click <code>Continue</code>.</p>
<p><img alt="ssh credentials slave" src="./images/ssh-credentials-slave.png" /></p>
<p>Select <code>Another user</code> and input <code>ec2-user</code>. Then select <code>Authentication Method</code> equals to <code>All hosts accept same private key</code>, click on <code>Choose File</code> and open <code>cloudera.pem</code> file. Click <code>Continue</code>. You will be asked: <code>Continue SSH login with no passphrase?</code>. Say: Ok!</p>
<h3>Installation in progress.</h3>
<p>Click <code>Continue</code>.</p>
<h3>Installing Selected Parcels</h3>
<p>Coffee time again (~5m). After coffee break click <code>Continue</code>.</p>
<h3>Inspect hosts</h3>
<p>Most probably you'll see the same errors as could be seen on the screenshot:</p>
<p><img alt="Inspect hosts on slave" src="./images/inspect-hosts.png" /></p>
<p>So, in order to fix them execute the following (slave instance):</p>
<p>```
sudo -s</p>
<p>sysctl vm.swappiness=10</p>
<p>echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</p>
<p>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</p>
<p>exit
```</p>
<p>Click on <code>Run Again</code> and see that the errors are absent. Click <code>Continue</code>.</p>
<h3>Choose a host template</h3>
<p><img alt="Host template" src="./images/host-template.png" /></p>
<p>Select <code>None</code>. And click <code>Continue</code>.</p>
<p><img alt="Deploy client configuration" src="./images/deploy-client-configuration-slave.png" /></p>
<p>Click <code>Finish</code>.</p>
<h3>HDFS configuration</h3>
<p>Go to <code>HDFS</code>, click <code>Actions</code> button and select <code>Add Role Instances</code>.</p>
<p><img alt="Role instances" src="./images/role-instances.png" /></p>
<p>Select <code>All Hosts</code> for <code>DataNode</code>.</p>
<p><img alt="Role instances" src="./images/hdfs-role-all-hosts.png" /></p>
<p>Click <code>Continue</code> and then click <code>Finish</code>.</p>
<p>On the top, near <code>Actions</code> button you'll see deployment icon. Click it.</p>
<p>On the next screen click <code>Refresh &amp; Deploy Client Config</code>. And click <code>Finish</code>.</p>
<h3>YARN configuration</h3>
<p>Go to <code>YARN (MR2 Included)</code>, click <code>Actions</code> button and select <code>Add Role Instances</code>.</p>
<p>Select <code>All Hosts</code> for <code>NodeManager</code>.</p>
<p>Click <code>Continue</code> and then click <code>Finish</code>.</p>
<p>On the top, near <code>Actions</code> button you'll see deployment icon. Click it.</p>
<p>On the next screen click <code>Deploy Client Configuration</code>. And click <code>Finish</code>.</p>
<h3>Start Roles on Hosts</h3>
<p>Go to <code>Hosts</code> -&gt; <code>All Hosts</code>. Select <code>slave.cloudera</code> link from the list. Click <code>Actions</code> button and select <code>Start Roles on Hosts</code>.</p>
<h3>Execute test application</h3>
<p>Connect to master instance:</p>
<p><code>ssh -i cloudera.pem ec2-user@master.cloudera</code></p>
<p>Then execute the following commands:</p>
<p><code>hadoop jar wordcount-1.0-SNAPSHOT-jar-with-dependencies.jar WordCount /home/root/wordcount/input /home/root/wordcount/output2</code></p>
<p>It is mostly the same as the previous one, except that the last argument is <code>/home/root/wordcount/output2</code> instead of <code>/home/root/wordcount/output</code>.</p>
<p>The following output could be seen in response:</p>
<p><code>16/11/02 07:13:55 INFO client.RMProxy: Connecting to ResourceManager at master.cloudera/172.30.191.118:8032
16/11/02 07:13:56 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/11/02 07:13:56 INFO input.FileInputFormat: Total input paths to process : 3
16/11/02 07:13:57 INFO mapreduce.JobSubmitter: number of splits:3
16/11/02 07:13:57 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1478081832568_0002
16/11/02 07:13:57 INFO impl.YarnClientImpl: Submitted application application_1478081832568_0002
16/11/02 07:13:57 INFO mapreduce.Job: The url to track the job: http://master.cloudera:8088/proxy/application_1478081832568_0002/
16/11/02 07:13:57 INFO mapreduce.Job: Running job: job_1478081832568_0002
16/11/02 07:14:07 INFO mapreduce.Job: Job job_1478081832568_0002 running in uber mode : false
16/11/02 07:14:07 INFO mapreduce.Job:  map 0% reduce 0%
16/11/02 07:14:13 INFO mapreduce.Job:  map 33% reduce 0%
16/11/02 07:14:19 INFO mapreduce.Job:  map 67% reduce 0%
16/11/02 07:14:25 INFO mapreduce.Job:  map 100% reduce 0%
16/11/02 07:14:34 INFO mapreduce.Job:  map 100% reduce 100%
16/11/02 07:14:35 INFO mapreduce.Job: Job job_1478081832568_0002 completed successfully
16/11/02 07:14:35 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=143
                FILE: Number of bytes written=490060
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=458
                HDFS: Number of bytes written=80
                HDFS: Number of read operations=12
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters 
                Launched map tasks=3
                Launched reduce tasks=1
                Data-local map tasks=3
                Total time spent by all maps in occupied slots (ms)=26090
                Total time spent by all reduces in occupied slots (ms)=13172
                Total time spent by all map tasks (ms)=13045
                Total time spent by all reduce tasks (ms)=6586
                Total vcore-seconds taken by all map tasks=13045
                Total vcore-seconds taken by all reduce tasks=6586
                Total megabyte-seconds taken by all map tasks=13358080
                Total megabyte-seconds taken by all reduce tasks=6744064
        Map-Reduce Framework
                Map input records=3
                Map output records=18
                Map output bytes=158
                Map output materialized bytes=224
                Input split bytes=372
                Combine input records=18
                Combine output records=17
                Reduce input groups=12
                Reduce shuffle bytes=224
                Reduce input records=17
                Reduce output records=12
                Spilled Records=34
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=222
                CPU time spent (ms)=2610
                Physical memory (bytes) snapshot=1553723392
                Virtual memory (bytes) snapshot=6366474240
                Total committed heap usage (bytes)=1410859008
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=86
        File Output Format Counters 
                Bytes Written=80</code></p>
<p>So far so good.</p>
<h3>Check the results of the execution</h3>
<p>Go to <code>YARN (MR2 Included)</code>, select <code>Applications</code>. You can see recently executed application.</p>
<p>Click <code>Web UI</code> -&gt; <code>Resource Manager Web UI (master)</code>.</p>
<p>Click <code>application_1478081832568_0002</code> application link.</p>
<p>Click <code>History</code> link.</p>
<p>Then click <code>3</code> link on the bottom of the page (<code>Maps</code> row, <code>Successful</code> column).</p>
<p><img alt="map attempts master and slave" src="./images/map-attempts-master-slave.png" /></p>
<p>Make sure that in the column <code>Node</code> there are present both master and slave!</p>
<p>That's all!</p>
</body>
</html>
